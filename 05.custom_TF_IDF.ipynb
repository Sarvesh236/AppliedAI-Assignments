{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407883ec",
   "metadata": {},
   "source": [
    "## Task - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "542663c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features from SKL :- ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "Features from custom code:- ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "\n",
      "\n",
      "IDF values from SKL :- [1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
      " 1.         1.91629073 1.        ]\n",
      "IDF values from custom code :- [1.916290731874155, 1.2231435513142097, 1.5108256237659907, 1.0, 1.916290731874155, 1.916290731874155, 1.0, 1.916290731874155, 1.0]\n",
      "\n",
      "\n",
      "shape of sklearn tfidf vectorizer output:  (4, 9)\n",
      "shape of custom code final output:  (4, 9)\n",
      "\n",
      "\n",
      "final output using SKL(First Row) :-   (0, 1)\t0.46979138557992045\n",
      "  (0, 2)\t0.5802858236844359\n",
      "  (0, 3)\t0.38408524091481483\n",
      "  (0, 6)\t0.38408524091481483\n",
      "  (0, 8)\t0.38408524091481483\n",
      "\n",
      "final output using custom code(First Row) :-   (0, 1)\t0.4697913855799205\n",
      "  (0, 2)\t0.580285823684436\n",
      "  (0, 3)\t0.3840852409148149\n",
      "  (0, 6)\t0.3840852409148149\n",
      "  (0, 8)\t0.3840852409148149\n",
      "\n",
      "\n",
      "final output using SKL(First Row,Dense Matrix) :- [[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n",
      "\n",
      "final output using custom code(First Row,Dense Matrix) :- [[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import operator\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def IDF(corpus, unique_words):\n",
    "    \"\"\"\n",
    "    This function calculates and return the IDF values.\n",
    "    \"\"\"\n",
    "    idf_dict={}\n",
    "    N=len(corpus)\n",
    "    for i in unique_words:\n",
    "        count=0\n",
    "        for sen in corpus:\n",
    "            if i in sen.split():  # checks if the word from unique_word present in the sentence\n",
    "                count=count+1     # and increment if it is there\n",
    "            idf_dict[i]=1+(math.log((1+N)/(count+1))) #IDF formula\n",
    "    return idf_dict\n",
    "\n",
    "def fit(dataset):\n",
    "    \"\"\"\n",
    "    This function creates dict of unique words in the corpus(vocab) and returns vocab and Idf values\n",
    "    \"\"\"\n",
    "    unique_words = set()     # at first we will initialize an empty set\n",
    "    if isinstance(dataset, (list,)):  # proceed if it is list\n",
    "        for row in dataset: \n",
    "            for word in row.split(\" \"):\n",
    "                if len(word) < 2:   # removes if the word is only one letter\n",
    "                    continue\n",
    "                unique_words.add(word) # Add the word to the set\n",
    "        unique_words = sorted(list(unique_words)) # convert set to list and sort it\n",
    "        vocab = {j:i for i,j in enumerate(unique_words)}   # dictionary of unique words of the corpus\n",
    "        \n",
    "    Idfs = IDF(dataset,unique_words)\n",
    "    return vocab, Idfs\n",
    "\n",
    "\n",
    "def transform(dataset,vocabulary,idf_values):\n",
    "    \"\"\"\n",
    "    This function calculates TF-IDF values and returns normalized sparse matrix of those values.\n",
    "    \"\"\"\n",
    "    sparse_matrix = csr_matrix( (len(dataset), len(vocabulary)), dtype=np.float64)\n",
    "    for row  in range(0,len(dataset)):\n",
    "        sen_words=Counter(dataset[row].split())  # words are stored as keys and their counts are stored as values.\n",
    "        for word in dataset[row].split():\n",
    "            if word in  list(vocabulary.keys()):\n",
    "                tf_idf_value=(sen_words[word]/len(dataset[row].split()))*(idf_values[word]) #Finding TF-IDF value\n",
    "                sparse_matrix[row,vocabulary[word]]=tf_idf_value  # converting to sparse matrix\n",
    "                \n",
    "    output = normalize(sparse_matrix, norm='l2', axis=1, copy=False, return_norm=False)  #Normalizing the final output\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "corpus = [\n",
    "     'this is the first document',\n",
    "     'this document is the second document',\n",
    "     'and this is the third one',\n",
    "     'is this the first document',\n",
    "]\n",
    "\n",
    "#using SKLearn\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(corpus)\n",
    "skl_output = vectorizer.transform(corpus)\n",
    "\n",
    "#Custom Code\n",
    "\n",
    "Vocabulary, idf_of_vocabulary = fit(corpus)\n",
    "\n",
    "print(\"Features from SKL :-\",vectorizer.get_feature_names())\n",
    "print(\"Features from custom code:-\",list(Vocabulary.keys()))\n",
    "\n",
    "print(\"\\n\\nIDF values from SKL :-\",vectorizer.idf_)\n",
    "print(\"IDF values from custom code :-\",list(idf_of_vocabulary.values()))\n",
    "\n",
    "final_output=transform(corpus,Vocabulary,idf_of_vocabulary)\n",
    "\n",
    "print(\"\\n\\nshape of sklearn tfidf vectorizer output: \",skl_output.shape)\n",
    "print(\"shape of custom code final output: \",final_output.shape)\n",
    "\n",
    "print(\"\\n\\nfinal output using SKL(First Row) :-\",skl_output[0].sorted_indices())\n",
    "print(\"\\nfinal output using custom code(First Row) :-\",final_output[0])\n",
    "\n",
    "print(\"\\n\\nfinal output using SKL(First Row,Dense Matrix) :-\",skl_output[0].toarray())\n",
    "print(\"\\nfinal output using custom code(First Row,Dense Matrix) :-\",final_output[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b19c1e",
   "metadata": {},
   "source": [
    "## Task - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d310b749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 Features:- ['aailiyah', 'abandoned', 'abroad', 'abstruse', 'academy', 'accents', 'accessible', 'acclaimed', 'accolades', 'accurate', 'accurately', 'achille', 'ackerman', 'actions', 'adams', 'add', 'added', 'admins', 'admiration', 'admitted', 'adrift', 'adventure', 'aesthetically', 'affected', 'affleck', 'afternoon', 'aged', 'ages', 'agree', 'agreed', 'aimless', 'aired', 'akasha', 'akin', 'alert', 'alike', 'allison', 'allow', 'allowing', 'alongside', 'amateurish', 'amaze', 'amazed', 'amazingly', 'amusing', 'amust', 'anatomist', 'angel', 'angela', 'angelina']\n",
      "\n",
      "Top 50 IDF values:- [6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872]\n",
      "\n",
      "shape of final output:  (746, 50)\n",
      "\n",
      "final output(First Row) :-   (0, 30)\t1.0\n",
      "\n",
      "final output(First Row,Dense Matrix) :- [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def fit_50(dataset):\n",
    "    \"\"\"\n",
    "    This function creates dict of unique words in the corpus(vocab) and returns vocab and Idf values\n",
    "    \"\"\"\n",
    "    top50_vocab = []\n",
    "    unique_words = set()     # at first we will initialize an empty set\n",
    "    if isinstance(dataset, (list,)):  # proceed if it is list\n",
    "        for row in dataset: \n",
    "            for word in row.split(\" \"):\n",
    "                if len(word) < 2:   # removes if the word is only one letter\n",
    "                    continue\n",
    "                unique_words.add(word) # Add the word to the set\n",
    "        unique_words = sorted(list(unique_words)) # convert set to list and sort it\n",
    "        \n",
    "    Idfs = IDF(dataset,unique_words)\n",
    "    \n",
    "    #extracting the top 50 words based on IDF values\n",
    "    sorted_idfs = {k: v for k, v in sorted(Idfs.items(), key=lambda item: item[1],reverse=True)} # sorting in descending order\n",
    "    top50_Idfs = {k: sorted_idfs[k] for k in list(sorted_idfs)[:50]}  # selecting first 50 elements from sorted idfs\n",
    "    for i in unique_words:           # getting the words with highest idf values\n",
    "        if i in top50_Idfs.keys():\n",
    "            top50_vocab.append(i)\n",
    "    top50_vocab = {j:i for i,j in enumerate(top50_vocab)}   # list to dictionary\n",
    "    return top50_vocab, top50_Idfs\n",
    "\n",
    "import pickle\n",
    "with open('cleaned_strings', 'rb') as f:\n",
    "    corpus1 = pickle.load(f)\n",
    "\n",
    "Vocabulary_50, idf_of_vocabulary_50 = fit_50(corpus1)\n",
    "\n",
    "print(\"Top 50 Features:-\",list(Vocabulary_50.keys()))\n",
    "print(\"\\nTop 50 IDF values:-\",list(idf_of_vocabulary_50.values()))\n",
    "\n",
    "final_output_50 = transform(corpus1,Vocabulary_50,idf_of_vocabulary_50)\n",
    "\n",
    "print(\"\\nshape of final output: \",final_output_50.shape)\n",
    "print(\"\\nfinal output(First Row) :-\",final_output_50[0])\n",
    "print(\"\\nfinal output(First Row,Dense Matrix) :-\",final_output_50[0].toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
